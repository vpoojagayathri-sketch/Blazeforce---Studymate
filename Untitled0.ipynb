{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/A/ZFxoeFLPs08TjvFt9l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"oY5ih27qJ3lw","executionInfo":{"status":"error","timestamp":1758288413773,"user_tz":-330,"elapsed":129,"user":{"displayName":"Pooja gayathri","userId":"09680201170809354089"}},"outputId":"3b399de5-95e6-42da-ce85-28f26348fd18"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'streamlit'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2252036848.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitz\u001b[0m  \u001b[0;31m# PyMuPDF instead of pypdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import streamlit as st\n","import fitz  # PyMuPDF instead of pypdf\n","import io\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import torch\n","import re\n","from datetime import datetime, timedelta\n","import json\n","import hashlib\n","from typing import List, Dict, Tuple\n","import time\n","\n","# Configure Streamlit page\n","st.set_page_config(\n","    page_title=\"StudyMate - AI PDF Q&A Assistant\",\n","    page_icon=\"üìö\",\n","    layout=\"wide\",\n","    initial_sidebar_state=\"expanded\"\n",")\n","\n","class StudyMate:\n","    def __init__(self):\n","        self.setup_model()\n","        self.initialize_session_state()\n","\n","    @st.cache_resource\n","    def setup_model(_self):\n","        \"\"\"Initialize the Granite model with caching for performance\"\"\"\n","        try:\n","            with st.spinner(\"Loading AI model... This may take a moment on first run.\"):\n","                tokenizer = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.3-2b-instruct\")\n","                model = AutoModelForCausalLM.from_pretrained(\n","                    \"ibm-granite/granite-3.3-2b-instruct\",\n","                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n","                    device_map=\"auto\" if torch.cuda.is_available() else None\n","                )\n","\n","                # Also create pipeline for easier use\n","                pipe = pipeline(\n","                    \"text-generation\",\n","                    model=model,\n","                    tokenizer=tokenizer,\n","                    max_new_tokens=512,\n","                    do_sample=True,\n","                    temperature=0.7,\n","                    pad_token_id=tokenizer.eos_token_id\n","                )\n","                return tokenizer, model, pipe\n","        except Exception as e:\n","            st.error(f\"Error loading model: {str(e)}\")\n","            return None, None, None\n","\n","    def initialize_session_state(self):\n","        \"\"\"Initialize session state variables\"\"\"\n","        if 'pdf_content' not in st.session_state:\n","            st.session_state.pdf_content = \"\"\n","        if 'pdf_sections' not in st.session_state:\n","            st.session_state.pdf_sections = []\n","        if 'flashcards' not in st.session_state:\n","            st.session_state.flashcards = []\n","        if 'study_plan' not in st.session_state:\n","            st.session_state.study_plan = {}\n","        if 'challenges' not in st.session_state:\n","            st.session_state.challenges = []\n","        if 'qa_history' not in st.session_state:\n","            st.session_state.qa_history = []\n","\n","    def extract_pdf_content(self, pdf_file) -> Tuple[str, List[Dict]]:\n","        \"\"\"Extract text content from PDF using PyMuPDF\"\"\"\n","        try:\n","            # Read PDF bytes\n","            pdf_bytes = pdf_file.read()\n","            pdf_document = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n","\n","            full_text = \"\"\n","            sections = []\n","\n","            for page_num in range(pdf_document.page_count):\n","                page = pdf_document[page_num]\n","                text = page.get_text()\n","                full_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\"\n","\n","                # Try to identify sections based on headings (simple heuristic)\n","                lines = text.split('\\n')\n","                for i, line in enumerate(lines):\n","                    line = line.strip()\n","                    if (len(line) > 10 and len(line) < 100 and\n","                        (line.isupper() or re.match(r'^(\\d+\\.|\\d+\\.\\d+)', line) or\n","                         any(keyword in line.lower() for keyword in ['chapter', 'section', 'introduction', 'conclusion']))):\n","\n","                        # Get some context after the heading\n","                        context_lines = lines[i+1:i+5]\n","                        context = ' '.join([l.strip() for l in context_lines if l.strip()])\n","\n","                        sections.append({\n","                            'title': line,\n","                            'page': page_num + 1,\n","                            'preview': context[:200] + \"...\" if len(context) > 200 else context\n","                        })\n","\n","            pdf_document.close()\n","            return full_text, sections\n","\n","        except Exception as e:\n","            st.error(f\"Error extracting PDF content: {str(e)}\")\n","            return \"\", []\n","\n","    def generate_ai_response(self, prompt: str, context: str = \"\", max_tokens: int = 400) -> Tuple[str, float]:\n","        \"\"\"Generate response using Granite model with confidence estimation\"\"\"\n","        tokenizer, model, pipe = self.setup_model()\n","\n","        if not pipe:\n","            return \"Error: AI model not available\", 0.0\n","\n","        try:\n","            # Construct the full prompt\n","            full_prompt = f\"\"\"Context: {context[:2000]}\n","\n","User Question: {prompt}\n","\n","Please provide a helpful and accurate answer based on the context provided. Be concise but informative.\"\"\"\n","\n","            messages = [{\"role\": \"user\", \"content\": full_prompt}]\n","\n","            # Generate response\n","            response = pipe(messages, max_new_tokens=max_tokens, do_sample=True, temperature=0.3)\n","            answer = response[0]['generated_text'][-1]['content'] if isinstance(response[0]['generated_text'], list) else response[0]['generated_text'].split(\"User Question:\")[-1].split(\"Please provide\")[-1]\n","\n","            # Simple confidence estimation based on response characteristics\n","            confidence = self.estimate_confidence(answer, context, prompt)\n","\n","            return answer.strip(), confidence\n","\n","        except Exception as e:\n","            return f\"Error generating response: {str(e)}\", 0.0\n","\n","    def estimate_confidence(self, answer: str, context: str, question: str) -> float:\n","        \"\"\"Estimate confidence in the AI response\"\"\"\n","        confidence_score = 0.5  # Base confidence\n","\n","        # Increase confidence if answer contains specific details\n","        if any(keyword in answer.lower() for keyword in ['specifically', 'according to', 'as stated', 'the document mentions']):\n","            confidence_score += 0.2\n","\n","        # Increase confidence if answer length suggests thoroughness\n","        if 50 < len(answer) < 300:\n","            confidence_score += 0.1\n","\n","        # Decrease confidence for very short or very long answers\n","        if len(answer) < 20 or len(answer) > 500:\n","            confidence_score -= 0.1\n","\n","        # Check if key terms from question appear in context\n","        question_words = set(question.lower().split())\n","        context_words = set(context.lower().split())\n","        overlap = len(question_words.intersection(context_words)) / len(question_words) if question_words else 0\n","        confidence_score += overlap * 0.2\n","\n","        # Ensure confidence is between 0 and 1\n","        return max(0.0, min(1.0, confidence_score))\n","\n","    def create_time_based_study_plan(self, days: int, content: str) -> Dict:\n","        \"\"\"Create a personalized study schedule\"\"\"\n","        sections = st.session_state.pdf_sections\n","\n","        if not sections:\n","            return {\"error\": \"No sections identified in the PDF\"}\n","\n","        # Simple algorithm to distribute sections across available days\n","        sections_per_day = max(1, len(sections) // max(1, days))\n","\n","        study_plan = {}\n","        current_date = datetime.now()\n","\n","        for day in range(days):\n","            date_str = (current_date + timedelta(days=day)).strftime(\"%Y-%m-%d\")\n","            start_idx = day * sections_per_day\n","            end_idx = min(start_idx + sections_per_day, len(sections))\n","\n","            day_sections = sections[start_idx:end_idx] if start_idx < len(sections) else []\n","\n","            study_plan[date_str] = {\n","                'day': day + 1,\n","                'sections': day_sections,\n","                'focus': 'Review and understand' if day < days - 2 else 'Final review and practice'\n","            }\n","\n","        return study_plan\n","\n","    def generate_flashcards(self, content: str) -> List[Dict]:\n","        \"\"\"Generate flashcards from PDF content\"\"\"\n","        prompt = f\"\"\"Based on the following content, identify important terms, concepts, and definitions that would be good for flashcards. Format each as \"Term: Definition\" pairs.\n","\n","Content: {content[:3000]}\n","\n","Please provide 5-10 flashcard pairs in this format:\n","Term: [term]\n","Definition: [definition]\n","\"\"\"\n","\n","        response, _ = self.generate_ai_response(prompt, content, max_tokens=500)\n","\n","        flashcards = []\n","        lines = response.split('\\n')\n","        current_term = \"\"\n","        current_definition = \"\"\n","\n","        for line in lines:\n","            line = line.strip()\n","            if line.startswith(\"Term:\"):\n","                if current_term and current_definition:\n","                    flashcards.append({\"term\": current_term, \"definition\": current_definition})\n","                current_term = line.replace(\"Term:\", \"\").strip()\n","                current_definition = \"\"\n","            elif line.startswith(\"Definition:\"):\n","                current_definition = line.replace(\"Definition:\", \"\").strip()\n","            elif current_term and not current_definition:\n","                current_definition = line\n","\n","        # Add the last flashcard if exists\n","        if current_term and current_definition:\n","            flashcards.append({\"term\": current_term, \"definition\": current_definition})\n","\n","        return flashcards\n","\n","    def generate_learning_challenges(self, content: str) -> List[Dict]:\n","        \"\"\"Generate gamified learning challenges\"\"\"\n","        prompt = f\"\"\"Based on this academic content, create 5 engaging daily/weekly study challenges that are fun and educational. Each challenge should test different aspects of learning.\n","\n","Content: {content[:2000]}\n","\n","Format each challenge as:\n","Challenge: [challenge description]\n","Type: [daily/weekly]\n","Difficulty: [easy/medium/hard]\n","\"\"\"\n","\n","        response, _ = self.generate_ai_response(prompt, content, max_tokens=400)\n","\n","        challenges = []\n","        lines = response.split('\\n')\n","        current_challenge = {}\n","\n","        for line in lines:\n","            line = line.strip()\n","            if line.startswith(\"Challenge:\"):\n","                if current_challenge:\n","                    challenges.append(current_challenge)\n","                current_challenge = {\"description\": line.replace(\"Challenge:\", \"\").strip()}\n","            elif line.startswith(\"Type:\"):\n","                current_challenge[\"type\"] = line.replace(\"Type:\", \"\").strip()\n","            elif line.startswith(\"Difficulty:\"):\n","                current_challenge[\"difficulty\"] = line.replace(\"Difficulty:\", \"\").strip()\n","\n","        if current_challenge:\n","            challenges.append(current_challenge)\n","\n","        return challenges\n","\n","    def summarize_sections(self, sections: List[Dict], content: str) -> List[Dict]:\n","        \"\"\"Generate summaries for each section\"\"\"\n","        summaries = []\n","\n","        for section in sections[:10]:  # Limit to first 10 sections\n","            prompt = f\"\"\"Summarize the following section in 3-5 bullet points. Be concise and focus on key concepts.\n","\n","Section: {section['title']}\n","Content: {section.get('preview', '')}\n","\n","Provide a clear summary in bullet points.\"\"\"\n","\n","            summary, confidence = self.generate_ai_response(prompt, content[:1000], max_tokens=200)\n","\n","            summaries.append({\n","                'title': section['title'],\n","                'page': section['page'],\n","                'summary': summary,\n","                'confidence': confidence\n","            })\n","\n","        return summaries\n","\n","def main():\n","    st.title(\"üìö StudyMate - AI-Powered PDF Q&A Assistant\")\n","    st.markdown(\"Upload your study materials and get intelligent answers, study plans, and more!\")\n","\n","    # Initialize StudyMate\n","    study_mate = StudyMate()\n","\n","    # Sidebar for file upload and features\n","    with st.sidebar:\n","        st.header(\"üìÅ Upload Your Study Material\")\n","        uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n","\n","        if uploaded_file is not None:\n","            with st.spinner(\"Processing PDF...\"):\n","                content, sections = study_mate.extract_pdf_content(uploaded_file)\n","                st.session_state.pdf_content = content\n","                st.session_state.pdf_sections = sections\n","                st.success(f\"PDF processed! Found {len(sections)} sections.\")\n","\n","        st.header(\"üéØ Features\")\n","        feature_options = [\n","            \"üí¨ Q&A Chat\",\n","            \"üìÖ Study Planner\",\n","            \"üéÆ Learning Challenges\",\n","            \"üìù Section Summaries\",\n","            \"üé¥ Flashcard Creator\"\n","        ]\n","        selected_feature = st.selectbox(\"Choose a feature:\", feature_options)\n","\n","    # Main content area\n","    if not st.session_state.pdf_content:\n","        st.info(\"üëÜ Please upload a PDF file to get started!\")\n","        st.markdown(\"\"\"\n","        ### Features Available:\n","        - **üí¨ Q&A Chat**: Ask questions about your PDF content\n","        - **üìÖ Study Planner**: Create time-based study schedules\n","        - **üéÆ Learning Challenges**: Get gamified learning activities\n","        - **üìù Section Summaries**: Get bullet-point summaries of sections\n","        - **üé¥ Flashcard Creator**: Generate flashcards for key terms\n","        \"\"\")\n","        return\n","\n","    # Feature implementations\n","    if selected_feature == \"üí¨ Q&A Chat\":\n","        st.header(\"üí¨ Ask Questions About Your PDF\")\n","\n","        # Display chat history\n","        for qa in st.session_state.qa_history:\n","            with st.chat_message(\"user\"):\n","                st.write(qa[\"question\"])\n","            with st.chat_message(\"assistant\"):\n","                st.write(qa[\"answer\"])\n","                if qa.get(\"confidence\"):\n","                    confidence_color = \"green\" if qa[\"confidence\"] > 0.7 else \"orange\" if qa[\"confidence\"] > 0.4 else \"red\"\n","                    st.markdown(f\"**Confidence:** :{confidence_color}[{qa['confidence']:.0%}]\")\n","\n","        # Chat input\n","        user_question = st.chat_input(\"Ask a question about your PDF content...\")\n","\n","        if user_question:\n","            with st.chat_message(\"user\"):\n","                st.write(user_question)\n","\n","            with st.chat_message(\"assistant\"):\n","                with st.spinner(\"Thinking...\"):\n","                    answer, confidence = study_mate.generate_ai_response(\n","                        user_question,\n","                        st.session_state.pdf_content\n","                    )\n","                    st.write(answer)\n","\n","                    # Display confidence meter\n","                    confidence_color = \"green\" if confidence > 0.7 else \"orange\" if confidence > 0.4 else \"red\"\n","                    st.markdown(f\"**AI Confidence:** :{confidence_color}[{confidence:.0%}]\")\n","\n","                    # Add to history\n","                    st.session_state.qa_history.append({\n","                        \"question\": user_question,\n","                        \"answer\": answer,\n","                        \"confidence\": confidence\n","                    })\n","\n","    elif selected_feature == \"üìÖ Study Planner\":\n","        st.header(\"üìÖ Time-Based Study Planner\")\n","\n","        col1, col2 = st.columns([1, 1])\n","        with col1:\n","            days_until_exam = st.number_input(\"Days until exam:\", min_value=1, max_value=365, value=7)\n","        with col2:\n","            if st.button(\"Create Study Plan\", type=\"primary\"):\n","                with st.spinner(\"Creating your personalized study plan...\"):\n","                    study_plan = study_mate.create_time_based_study_plan(\n","                        days_until_exam,\n","                        st.session_state.pdf_content\n","                    )\n","                    st.session_state.study_plan = study_plan\n","\n","        if st.session_state.study_plan:\n","            st.subheader(\"üìã Your Personalized Study Schedule\")\n","\n","            for date, plan in st.session_state.study_plan.items():\n","                if isinstance(plan, dict) and 'sections' in plan:\n","                    with st.expander(f\"üìÖ Day {plan['day']} - {date}\"):\n","                        st.markdown(f\"**Focus:** {plan['focus']}\")\n","                        st.markdown(\"**Sections to cover:**\")\n","                        for section in plan['sections']:\n","                            st.markdown(f\"- {section['title']} (Page {section['page']})\")\n","                            if section.get('preview'):\n","                                st.markdown(f\"  *Preview: {section['preview'][:100]}...*\")\n","\n","    elif selected_feature == \"üéÆ Learning Challenges\":\n","        st.header(\"üéÆ Gamified Learning Challenges\")\n","\n","        if st.button(\"Generate New Challenges\", type=\"primary\"):\n","            with st.spinner(\"Creating fun learning challenges...\"):\n","                challenges = study_mate.generate_learning_challenges(st.session_state.pdf_content)\n","                st.session_state.challenges = challenges\n","\n","        if st.session_state.challenges:\n","            st.subheader(\"üèÜ Your Learning Challenges\")\n","\n","            for i, challenge in enumerate(st.session_state.challenges, 1):\n","                with st.container():\n","                    st.markdown(f\"### Challenge {i}\")\n","                    st.markdown(f\"**üìã Task:** {challenge.get('description', 'No description available')}\")\n","\n","                    col1, col2 = st.columns(2)\n","                    with col1:\n","                        challenge_type = challenge.get('type', 'daily')\n","                        if 'daily' in challenge_type.lower():\n","                            st.markdown(\"‚è∞ **Type:** Daily\")\n","                        else:\n","                            st.markdown(\"üìÖ **Type:** Weekly\")\n","\n","                    with col2:\n","                        difficulty = challenge.get('difficulty', 'medium').lower()\n","                        if 'easy' in difficulty:\n","                            st.markdown(\"üü¢ **Difficulty:** Easy\")\n","                        elif 'hard' in difficulty:\n","                            st.markdown(\"üî¥ **Difficulty:** Hard\")\n","                        else:\n","                            st.markdown(\"üü° **Difficulty:** Medium\")\n","\n","                    st.markdown(\"---\")\n","\n","    elif selected_feature == \"üìù Section Summaries\":\n","        st.header(\"üìù Section Summaries\")\n","\n","        if st.button(\"Generate Summaries\", type=\"primary\"):\n","            with st.spinner(\"Creating section summaries...\"):\n","                summaries = study_mate.summarize_sections(\n","                    st.session_state.pdf_sections,\n","                    st.session_state.pdf_content\n","                )\n","                st.session_state.section_summaries = summaries\n","\n","        if hasattr(st.session_state, 'section_summaries'):\n","            st.subheader(\"üìã PDF Section Summaries\")\n","\n","            for summary in st.session_state.section_summaries:\n","                with st.expander(f\"üìñ {summary['title']} (Page {summary['page']})\"):\n","                    st.markdown(summary['summary'])\n","\n","                    # Confidence indicator\n","                    confidence = summary.get('confidence', 0.5)\n","                    confidence_color = \"green\" if confidence > 0.7 else \"orange\" if confidence > 0.4 else \"red\"\n","                    st.markdown(f\"**Summary Confidence:** :{confidence_color}[{confidence:.0%}]\")\n","\n","    elif selected_feature == \"üé¥ Flashcard Creator\":\n","        st.header(\"üé¥ Flashcard Creator\")\n","\n","        if st.button(\"Generate Flashcards\", type=\"primary\"):\n","            with st.spinner(\"Creating flashcards from your PDF...\"):\n","                flashcards = study_mate.generate_flashcards(st.session_state.pdf_content)\n","                st.session_state.flashcards = flashcards\n","\n","        if st.session_state.flashcards:\n","            st.subheader(\"üÉè Generated Flashcards\")\n","\n","            # Display flashcards\n","            for i, card in enumerate(st.session_state.flashcards, 1):\n","                with st.container():\n","                    st.markdown(f\"### Card {i}\")\n","\n","                    col1, col2 = st.columns([1, 2])\n","                    with col1:\n","                        st.markdown(\"**üè∑Ô∏è Term:**\")\n","                        st.info(card.get('term', 'No term'))\n","\n","                    with col2:\n","                        st.markdown(\"**üìù Definition:**\")\n","                        st.success(card.get('definition', 'No definition'))\n","\n","                    st.markdown(\"---\")\n","\n","            # Export options\n","            st.subheader(\"üì§ Export Flashcards\")\n","            col1, col2 = st.columns(2)\n","\n","            with col1:\n","                # Anki format\n","                anki_text = \"\"\n","                for card in st.session_state.flashcards:\n","                    anki_text += f\"{card.get('term', '')}\\t{card.get('definition', '')}\\n\"\n","\n","                st.download_button(\n","                    label=\"üì• Download for Anki\",\n","                    data=anki_text,\n","                    file_name=\"studymate_flashcards.txt\",\n","                    mime=\"text/plain\"\n","                )\n","\n","            with col2:\n","                # JSON format\n","                json_data = json.dumps(st.session_state.flashcards, indent=2)\n","                st.download_button(\n","                    label=\"üì• Download as JSON\",\n","                    data=json_data,\n","                    file_name=\"studymate_flashcards.json\",\n","                    mime=\"application/json\"\n","                )\n","\n","if __name__ == \"__main__\":\n","    main()\n",""]},{"cell_type":"code","metadata":{"id":"338532a3"},"source":["%pip install streamlit"],"execution_count":null,"outputs":[]}]}